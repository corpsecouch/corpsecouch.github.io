import{_ as s,c as l,d as a,g as r,w as i,a as t,e as o,f as h,o as p}from"./chunks/framework.D6M9R-ut.js";const d="/assets/hero.BIXjHIVu.jpg",c="/assets/one.BLrUCXlF.jpg",u="/assets/two.SwA4dnd2.gif",v=JSON.parse('{"title":"The Mixed Reality Prototyping Tool Designers Need","description":"","frontmatter":{"title":"The Mixed Reality Prototyping Tool Designers Need","date":"2017-04-12T12:00","layout":"article","head":[["link",{"rel":"canonical","href":"https://jasonbejot.com/articles/the-mixed-reality-prototyping-tool-designers-need/"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"57x57","href":"/apple-touch-icon-57x57.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"60x60","href":"/apple-touch-icon-60x60.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"72x72","href":"/apple-touch-icon-72x72.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"76x76","href":"/apple-touch-icon-76x76.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"114x114","href":"/apple-touch-icon-114x114.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"120x120","href":"/apple-touch-icon-120x120.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"144x144","href":"/apple-touch-icon-144x144.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"152x152","href":"/apple-touch-icon-152x152.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"167x167","href":"/apple-touch-icon-167x167.png"}],["link",{"rel":"apple-touch-icon-precomposed","sizes":"180x180","href":"/apple-touch-icon-180x180.png"}],["link",{"rel":"icon","type":"image/png","sizes":"32x32","href":"/favicon-32x32.png"}],["link",{"rel":"icon","type":"image/png","sizes":"16x16","href":"/favicon-16x16.png"}],["link",{"rel":"icon","type":"image/png","sizes":"96x96","href":"/favicon-96x96.png"}],["link",{"rel":"icon","type":"image/png","sizes":"128x128","href":"/favicon-128x128.png"}],["link",{"rel":"icon","type":"image/png","sizes":"196x196","href":"/favicon-196x196.png"}]]},"headers":[],"relativePath":"articles/the-mixed-reality-prototyping-tool-designers-need/index.md","filePath":"articles/archive/the-mixed-reality-prototyping-tool-designers-need/index.md"}'),g={name:"articles/the-mixed-reality-prototyping-tool-designers-need/index.md"};function m(f,e,x,y,b,k){const n=h("Illustration");return p(),l("div",null,[e[4]||(e[4]=a('<p><img src="'+d+'" alt=""></p><p>Mixed Reality is the next big experience technology but there are no tools for experience designers. The design community has just recently been breaking into VR in a big way. We’re seeing steady stream of early tools and techniques emerging, but just for VR. To really push mixed reality out of the labs and into the streets designers need to sink their teeth into it. For that they need tools.</p><p>The ideal mixed reality prototyping tool chain needs to be quick, effortless and have a super low learning curve. Being an experience architect and having developed 3D and AR engines I understand the complexities from both sides. So here are my thoughts on what the first mixed reality tool the experience design community needs.</p><h2 id="rapid-preview-testing" tabindex="-1">Rapid Preview / Testing <a class="header-anchor" href="#rapid-preview-testing" aria-label="Permalink to &quot;Rapid Preview / Testing&quot;">​</a></h2><p>Just like when a developer hits build in their IDE to make sure their code works, designers need to quickly move from design software to a preview make sure their design works. This sort of rapid desk testing will be key.</p><h2 id="hide-the-tool-chain" tabindex="-1">Hide The Tool Chain <a class="header-anchor" href="#hide-the-tool-chain" aria-label="Permalink to &quot;Hide The Tool Chain&quot;">​</a></h2><p>The focus is on the design and the experience that emerges, keep the tools out of the way. There shouldn’t be a need to jump through multiple tools or manage background processes. The tool should be self contained. If it does have dependencies it should be auto-manage them or handle them some graceful way. The last thing someone wants to do is spend hours troubleshooting what thing broke in their tool chain, or why, just to preview something.</p><h2 id="integrate-with-current-2d-design-tools" tabindex="-1">Integrate With Current 2D Design Tools <a class="header-anchor" href="#integrate-with-current-2d-design-tools" aria-label="Permalink to &quot;Integrate With Current 2D Design Tools&quot;">​</a></h2><p>There’s the hard-line stance of “just learn Unity or SketchUp”. However, the majority of designers work and think in two dimensions. Designing in three dimensions, learning new tools and workflows is incredibly expensive and time consuming. Especially if you’re just dipping your toes in to see if want to do this type of design. The ideal MR prototyping tool needs to seamlessly integrate with what designers already know, like Sketch.</p><h2 id="mr-specific-device-not-required" tabindex="-1">MR-specific Device Not Required <a class="header-anchor" href="#mr-specific-device-not-required" aria-label="Permalink to &quot;MR-specific Device Not Required&quot;">​</a></h2><p>Access to a Hololens, Meta2 or other mixed reality device shouldn’t be the hurdle to creating mixed reality experiences. The ideal tool should be able to use widely available devices, like smartphones. Yes, MR experiences are different between, for example, a Hololens and an iPhone. Being able to rapidly test on a iPhone before moving to a Hololens is still extremely valuable.</p>',11)),r(n,null,{image:i(()=>e[0]||(e[0]=[t("p",null,[t("img",{src:c,alt:""})],-1)])),subtext:i(()=>e[1]||(e[1]=[o("Goggles not required for rapid testing")])),_:1}),e[5]||(e[5]=t("h2",{id:"utilize-the-device-camera",tabindex:"-1"},[o("Utilize The Device Camera "),t("a",{class:"header-anchor",href:"#utilize-the-device-camera","aria-label":'Permalink to "Utilize The Device Camera"'},"​")],-1)),e[6]||(e[6]=t("p",null,"This is the one thing that none of the VR prototyping tools enable, yet. If you can test on a phone then enable the camera and pass the feed through to the preview. It’s not perfect but it at least get’s the designer one step closer to the actual experience.",-1)),e[7]||(e[7]=t("h2",{id:"simulate-user-interactions",tabindex:"-1"},[o("Simulate User Interactions "),t("a",{class:"header-anchor",href:"#simulate-user-interactions","aria-label":'Permalink to "Simulate User Interactions"'},"​")],-1)),e[8]||(e[8]=t("p",null,"Mixed reality experiences need interactions because people want to touch what they see. When your prototyping you need the ability to simulate all sorts of interactions: touch, gestures, etc.",-1)),r(n,null,{image:i(()=>e[2]||(e[2]=[t("p",null,[t("img",{src:u,alt:""})],-1)])),subtext:i(()=>e[3]||(e[3]=[o("Gotta drag that shoe around somehow")])),_:1}),e[9]||(e[9]=a('<h2 id="simulate-context" tabindex="-1">Simulate Context <a class="header-anchor" href="#simulate-context" aria-label="Permalink to &quot;Simulate Context&quot;">​</a></h2><p>The heart of all mixed reality experiences is it’s context. Where, when, what does it see, what does the user see, is the mixed part of the reality blocking a critical or dangerous part actual reality? The MR prototyping tool needs to have a robust way of simulating different contexts. The designer and developer won’t always be able to create in the context the experience will be used to do rapid desk testing. For instance, if the MR experience is for fire fighters you won’t find designers on their laptop in the middle of a burning building. Maybe metaphorically, but not literally. The tool needs to support that.</p><h2 id="simulate-real-world-object-mixing" tabindex="-1">Simulate Real-World Object Mixing <a class="header-anchor" href="#simulate-real-world-object-mixing" aria-label="Permalink to &quot;Simulate Real-World Object Mixing&quot;">​</a></h2><p>Mixed reality is all about mixing real world objects with digital artifacts. So of course the tool needs to do that. Since it’s a prototyping tool it probably shouldn’t be as robust as a production application. QR-style tracking markers or limited 3D pattern recognition should suffice. It would also allow for lots of flexibility and creativity with testing.</p><p>Imagine an MR experience where real world cars turn into palm trees. Stick 2D markers to a bunch of cardboard cut-outs then your co-workers can play bumper cars when you test.</p><h2 id="let-s-make-this-happen" tabindex="-1">Let’s Make This Happen <a class="header-anchor" href="#let-s-make-this-happen" aria-label="Permalink to &quot;Let’s Make This Happen&quot;">​</a></h2><p>This sounds like an exhaustive list and there are probably plethora of other features that designers would want. I think this list is a great start and I can already see it forming in my minds-eye. Hopefully the design community sees something like this emerge in the near future.</p>',7))])}const T=s(g,[["render",m]]);export{v as __pageData,T as default};
